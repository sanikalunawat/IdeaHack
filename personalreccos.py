# -*- coding: utf-8 -*-
"""PersonalReccos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PIODvXoHJ_xztfKvRoduWzbmM1Mk5RRJ
"""

!pip install pandas numpy faker scikit-learn

import random
from faker import Faker
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report

# Initialize Faker
fake = Faker()

# Define transaction categories
categories = ["shopping", "travel", "dining", "bills", "groceries", "entertainment"]

# Function to generate synthetic transaction data for users
def generate_transactions(num_users=500):
    transactions = []
    # Create a list of unique user IDs
    user_ids = [fake.uuid4() for _ in range(num_users)]

    for user_id in user_ids:
        # For each user, generate a random number of transactions between 5 and 20
        num_transactions = random.randint(5, 20)
        for _ in range(num_transactions):
            transaction = {
                "user_id": user_id,
                "transaction_date": fake.date_time_between(start_date='-1y', end_date='now'),
                "category": random.choice(categories),
                "amount": round(random.uniform(10, 500), 2)
            }
            transactions.append(transaction)
    return pd.DataFrame(transactions)

# Generate synthetic transactions
df_transactions = generate_transactions(num_users=500)

# Aggregate transaction counts per user and per category (using all transactions)
agg_df = df_transactions.groupby(['user_id', 'category']).size().unstack(fill_value=0).reset_index()

# Ensure all category columns exist (if a category is missing for a user)
for cat in categories:
    if cat not in agg_df.columns:
        agg_df[cat] = 0

# Modified recommendation function to return multiple cards if conditions are met
def assign_recommendation(row):
    recommendations = []
    if row.get("shopping", 0) > 3:
        recommendations.append("Credit Card Cashback")
    if row.get("travel", 0) > 3:
        recommendations.append("Travel Rewards Credit Card")
    if row.get("dining", 0) > 4:
        recommendations.append("Dining Discount Card")
    if row.get("bills", 0) > 2:
        recommendations.append("Utility Rewards Card")
    if row.get("groceries", 0) > 3:
        recommendations.append("Debit Card with Grocery Cashback")
    if row.get("entertainment", 0) > 3:
        recommendations.append("Entertainment Offers Card")

    return ", ".join(recommendations) if recommendations else "No recommendation"

# Apply the recommendation logic for each user (on full aggregated history)
agg_df['recommendation'] = agg_df.apply(assign_recommendation, axis=1)

print("Sample aggregated data with recommendations:")
print(agg_df.head())

# Use aggregated counts as features and the assigned recommendations as the target.
X = agg_df[categories]
y = agg_df['recommendation']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train a Decision Tree Classifier
clf = DecisionTreeClassifier(random_state=42)
clf.fit(X_train, y_train)

# Make predictions on the test set and evaluate the model
y_pred = clf.predict(X_test)
print("\nModel Classification Report:")
print(classification_report(y_test, y_pred))

# Calculate and print accuracy separately
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: {:.2f}%".format(accuracy * 100))

# Optionally, display feature importances
feature_importances = pd.Series(clf.feature_importances_, index=categories)
print("\nFeature Importances:")
print(feature_importances.sort_values(ascending=False))

# 1. Pick a random user from the aggregated data
test_user = agg_df.sample(1).iloc[0]
user_id = test_user['user_id']
print(f"\n---\nTesting recommendation for User ID: {user_id}")

# Retrieve all transactions for that user and sort them by date
user_transactions = df_transactions[df_transactions['user_id'] == user_id]
user_transactions_sorted = user_transactions.sort_values(by='transaction_date')

# Take only the last 10 transactions (or all if less than 10)
last_10_transactions = user_transactions_sorted.tail(10)
print("\nUser's last 10 transaction history:")
print(last_10_transactions)

# Recalculate aggregated counts for the last 10 transactions only
test_agg = last_10_transactions.groupby('category').size().to_dict()
features = {cat: test_agg.get(cat, 0) for cat in categories}
test_features_df = pd.DataFrame([features])
print("\nAggregated transaction counts for the last 10 transactions:")
print(test_features_df)

# Predict the recommended cards using the trained model
predicted_recommendation = clf.predict(test_features_df)[0]
print(f"\nRecommended Cards for User {user_id}: {predicted_recommendation}")